{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed9b11a0-101f-4046-ae90-537cf2a91447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unstructured', 'data', 'processing', 'with', 'Python', 'is', 'powerful', '!']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# nltk.download(\"punkt_tab\")\n",
    "text = \"Unstructured data processing with Python is powerful!\"\n",
    "tokens = word_tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1777d77-77c2-4dff-b33f-e9a21fe1b4ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/Dell/Desktop/Python Practice/source_datafiles/unstructured_data.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# extracting text from pdf file pages\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpdfplumber\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mpdfplumber\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC:/Users/Dell/Desktop/Python Practice/source_datafiles/unstructured_data.pdf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m pdf:\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m pdf.pages:\n\u001b[32m      5\u001b[39m         \u001b[38;5;28mprint\u001b[39m(page.extract_text())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dell\\miniconda3\\Lib\\site-packages\\pdfplumber\\pdf.py:98\u001b[39m, in \u001b[36mPDF.open\u001b[39m\u001b[34m(cls, path_or_fp, pages, laparams, password, strict_metadata, unicode_norm, repair, gs_path, repair_setting, raise_unicode_errors)\u001b[39m\n\u001b[32m     96\u001b[39m     path = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_fp, (\u001b[38;5;28mstr\u001b[39m, pathlib.Path)):\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m     stream = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath_or_fp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m     stream_is_external = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    100\u001b[39m     path = pathlib.Path(path_or_fp)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'C:/Users/Dell/Desktop/Python Practice/source_datafiles/unstructured_data.pdf'"
     ]
    }
   ],
   "source": [
    "# extracting text from pdf file pages\n",
    "import pdfplumber\n",
    "with pdfplumber.open(\"C:/Users/Dell/Desktop/Python Practice/source_datafiles/unstructured_data.pdf\") as pdf:\n",
    "    for page in pdf.pages:\n",
    "        print(page.extract_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1292ef-3a5b-48c5-88b1-dba3cf99c98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download NLTK resources (only needed first time)\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e79060-408f-42be-833a-6ef615514a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "print(\"‚úÖ Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06f24cc-6afc-4bf0-b798-2b6225a0d880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìò Unstructured Data Processing Starter Notebook\n",
    "\n",
    "# ==============\n",
    "# 1. Setup\n",
    "# ==============\n",
    "import nltk\n",
    "import spacy\n",
    "import pdfplumber\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Download NLTK resources (only needed first time)\n",
    "# nltk.download(\"punkt\")\n",
    "# nltk.download(\"stopwords\")\n",
    "\n",
    "# Load spaCy model (needs download: python -m spacy download en_core_web_sm)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")\n",
    "\n",
    "# ==============\n",
    "# 2. Text Processing\n",
    "# ==============\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "text = \"Unstructured data processing with Python is powerful and flexible!\"\n",
    "\n",
    "# Tokenize\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# Remove stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "filtered = [w for w in tokens if w.lower() not in stop_words]\n",
    "\n",
    "print(\"Original Text:\", text)\n",
    "print(\"Tokens:\", tokens)\n",
    "print(\"Filtered:\", filtered)\n",
    "\n",
    "# spaCy Named Entity Recognition\n",
    "doc = nlp(text)\n",
    "print(\"\\nNamed Entities:\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, \"‚Üí\", ent.label_)\n",
    "\n",
    "# ==============\n",
    "# 3. PDF Processing\n",
    "# ==============\n",
    "pdf_path = \"unstructured_data.pdf\"  # PDF file containing text\n",
    "try:\n",
    "    with pdfplumber.open(\"C:/Users/Dell/Desktop/Python Practice/source_datafiles/unstructured_data.pdf\") as pdf:\n",
    "        first_page = pdf.pages[0]\n",
    "        pdf_text = first_page.extract_text()\n",
    "        print(\"\\nExtracted text from PDF:\\n\", pdf_text)\n",
    "except Exception as e:\n",
    "    print(\"‚ö†Ô∏è Could not open PDF:\", e)\n",
    "\n",
    "# ==============\n",
    "# 4. Image Processing\n",
    "# ==============\n",
    "\n",
    "img_path = \"C:/Users/Dell/Desktop/Python Practice/source_datafiles/mypic.jpg\"  # replace with your image\n",
    "\n",
    "try:\n",
    "    # Open image with Pillow\n",
    "    img = Image.open(img_path)\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    # Convert to grayscale with OpenCV\n",
    "    cv_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    plt.imshow(cv_img, cmap=\"gray\")\n",
    "    plt.title(\"Grayscale Image\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    print(\"‚úÖ Image processed successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"‚ö†Ô∏è Could not process image:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e111153-3de5-48b9-b04d-c82744de8fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your PDF\n",
    "pdf_path = r\"C:\\Users\\Dell\\Desktop\\Python Practice\\outputfiles\\generated invoices/invoice_1.pdf\"\n",
    "\n",
    "# all tables in pdf\n",
    "all_tables = []\n",
    "\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    for page_number, page in enumerate(pdf.pages, start=1):\n",
    "        # Extract tables on this page\n",
    "        tables = page.extract_tables()\n",
    "       \n",
    "        for table_number, table in enumerate(tables, start=1):\n",
    "            # Convert table to DataFrame (layout preserved)\n",
    "            df_tables= pd.DataFrame(table[1:], columns=table[0]);\n",
    "            df = pd.DataFrame(table[1:], columns=table[0])\n",
    "            df['Page'] = page_number  # Optional: keep track of page\n",
    "            df['Table_Number'] = table_number\n",
    "            all_tables.append(df)\n",
    "\n",
    "# Combine all tables if needed\n",
    "if all_tables:\n",
    "    final_df = pd.concat(all_tables, ignore_index=True)\n",
    "else:\n",
    "    final_df = pd.DataFrame()\n",
    "\n",
    "# Show table\n",
    "print (df_tables)\n",
    "\n",
    "print(final_df)\n",
    "\n",
    "# Optionally save to Excel/CSV\n",
    "final_df.to_excel(r\"C:\\Users\\Dell\\Desktop\\Python Practice\\outputfiles\\generated invoices text\\output_invoice_tables.xlsx\", index=False)\n",
    "final_df.to_csv(r\"C:\\Users\\Dell\\Desktop\\Python Practice\\outputfiles\\generated invoices text\\output_invoice_tables.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482f26d8-8e0a-4771-8a3e-9cab606f205c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.platypus import Table, TableStyle\n",
    "from reportlab.lib import colors\n",
    "\n",
    "# File path to save PDF\n",
    "pdf_path = r\"C:\\Users\\Dell\\Desktop\\Python Practice\\source_datafiles\\pdfs/ebay Rechnung_NEW.pdf\"\n",
    "\n",
    "# Sample invoice data\n",
    "data = [\n",
    "    [\"Item\", \"Description\", \"Quantity\", \"Unit Price\", \"Total\"],\n",
    "    [\"001\", \"Laptop\", 2, \"$800\", \"$1600\"],\n",
    "    [\"002\", \"Mouse\", 5, \"$20\", \"$100\"],\n",
    "    [\"003\", \"Keyboard\", 3, \"$30\", \"$90\"],\n",
    "    [\"004\", \"Monitor\", 2, \"$150\", \"$300\"],\n",
    "    [\"005\", \"USB Cable\", 10, \"$5\", \"$50\"]\n",
    "]\n",
    "\n",
    "# Create PDF\n",
    "c = canvas.Canvas(pdf_path, pagesize=A4)\n",
    "width, height = A4\n",
    "\n",
    "# Title\n",
    "c.setFont(\"Helvetica-Bold\", 20)\n",
    "c.drawString(50, height - 50, \"Sample Invoice\")\n",
    "\n",
    "# Draw table\n",
    "table = Table(data, colWidths=[80, 200, 60, 80, 80])\n",
    "style = TableStyle([\n",
    "    ('BACKGROUND', (0, 0), (-1, 0), colors.lightblue),\n",
    "    ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),\n",
    "    ('ALIGN', (2, 1), (-1, -1), 'CENTER'),\n",
    "    ('GRID', (0, 0), (-1, -1), 1, colors.black),\n",
    "    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold')\n",
    "])\n",
    "table.setStyle(style)\n",
    "\n",
    "# Position table on page\n",
    "table.wrapOn(c, width, height)\n",
    "table.drawOn(c, 50, height - 250)\n",
    "\n",
    "# Footer\n",
    "c.setFont(\"Helvetica\", 10)\n",
    "c.drawString(50, 50, \"Thank you for your business!\")\n",
    "\n",
    "# Save PDF\n",
    "c.save()\n",
    "\n",
    "print(f\"PDF invoice saved at: {pdf_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ad844c-901c-4c32-b642-339cb29faaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "mp3_path = r\"C:\\Users\\Dell\\Desktop\\Python Practice\\source_datafiles\\Audio Files\\audiofile.mp3\"\n",
    "Audio(mp3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3af99e0-bbcc-4bf3-ba26-62fd9575b0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.utils import which\n",
    "\n",
    "# Provide path to ffmpeg.exe\n",
    "AudioSegment.converter = r\"C:\\ffmpeg\\bin\\ffmpeg.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc8a1f1-f5ac-4041-8b2a-db767488fb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install whisper if not installed\n",
    "# !pip install openai-whisper\n",
    "\n",
    "import whisper\n",
    "\n",
    "# 1Ô∏è‚É£ Load the Whisper model\n",
    "model = whisper.load_model(\"base\")  # choose \"tiny\", \"base\", \"small\", \"medium\", \"large\"\n",
    "\n",
    "# 2Ô∏è‚É£ Path to your MP3 file\n",
    "mp3_path = r\"C:\\Users\\Dell\\Desktop\\Python Practice\\source_datafiles\\Audio Files\\audiofile.mp3\"\n",
    "\n",
    "# 3Ô∏è‚É£ Transcribe audio directly from MP3\n",
    "result = model.transcribe(mp3_path)\n",
    "\n",
    "# 4Ô∏è‚É£ Get the transcribed text\n",
    "text = result[\"text\"]\n",
    "\n",
    "# 5Ô∏è‚É£ Print the text\n",
    "print(\"üé§ Transcribed Text:\\n\")\n",
    "print(text)\n",
    "\n",
    "# 6Ô∏è‚É£ Optionally save to a text file\n",
    "txt_path = r\"C:\\Users\\Dell\\Desktop\\Python Practice\\outputfiles\\audioTOtext\\audiofile.txt\"\n",
    "with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(text)\n",
    "\n",
    "print(\"\\n‚úÖ Transcription saved to:\", txt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d98cd12-5f4b-4053-9cf3-ab92026b685e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE PDF File into database\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your PDF\n",
    "pdf_path = r\"C:/Users/Dell/Desktop/Python Practice/outputfiles/invoice_1.pdf\"\n",
    "\n",
    "# all tables in pdf\n",
    "all_tables = []\n",
    "\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    for page_number, page in enumerate(pdf.pages, start=1):\n",
    "        # Extract tables on this page\n",
    "        tables = page.extract_tables()\n",
    "       \n",
    "        for table_number, table in enumerate(tables, start=1):\n",
    "            # Convert table to DataFrame (layout preserved)\n",
    "            df_tables= pd.DataFrame(table[1:], columns=table[0]);\n",
    "            df = pd.DataFrame(table[1:], columns=table[0])\n",
    "            df['Page'] = page_number  # Optional: keep track of page\n",
    "            df['Table_Number'] = table_number\n",
    "            all_tables.append(df)\n",
    "\n",
    "# Combine all tables if needed\n",
    "if all_tables:\n",
    "    final_df = pd.concat(all_tables, ignore_index=True)\n",
    "else:\n",
    "    final_df = pd.DataFrame()\n",
    "\n",
    "# Show table\n",
    "print (df_tables)\n",
    "\n",
    "print(final_df)\n",
    "\n",
    "# Optionally save to Excel/CSV\n",
    "final_df.to_excel(r\"C:\\Users\\Dell\\Desktop\\Python Practice\\Outputfiles\\output_invoice_tables.xlsx\", index=False)\n",
    "final_df.to_csv(r\"C:\\Users\\Dell\\Desktop\\Python Practice\\Outputfiles\\output_invoice_tables.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "\n",
    "# 1Ô∏è‚É£ Create a sample DataFrame\n",
    "data = {\n",
    "    \"EmployeeID\": [1, 2, 3],\n",
    "    \"Name\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
    "    \"Department\": [\"HR\", \"IT\", \"Finance\"],\n",
    "    \"Salary\": [50000, 60000, 55000]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 2Ô∏è‚É£ Define SQL Server connection parameters\n",
    "server = '(localdb)\\MSSQLLocalDB'        # Or 'localhost\\SQLEXPRESS' if using SQL Express\n",
    "database = 'Arsipa'         # Your database name\n",
    "username = 'sa'             # SQL Server username\n",
    "password = '123'   # SQL Server password\n",
    "driver = '{ODBC Driver 17 for SQL Server}'  # Make sure this driver is installed\n",
    "\n",
    "# 3Ô∏è‚É£ Connect to SQL Server\n",
    "# conn_str with SQL Server User Authentication\n",
    "# conn_str = f'DRIVER={driver};SERVER={server};DATABASE={database};UID={username};PWD={password}'\n",
    "\n",
    "# conn_str with Windows Authntication\n",
    "conn_str = f'DRIVER={driver};SERVER={server};DATABASE={database};Trusted_Connection=yes;'\n",
    "conn = pyodbc.connect(conn_str)\n",
    "cursor = conn.cursor()\n",
    "print(\"‚úÖ Connected to SQL Server\")\n",
    "\n",
    "# 4Ô∏è‚É£ Create table (if not exists)\n",
    "create_table_query = \"\"\"\n",
    "IF NOT EXISTS (SELECT * FROM sysobjects WHERE name='Employees' AND xtype='U')\n",
    "CREATE TABLE Employees (\n",
    "    EmployeeID INT PRIMARY KEY,\n",
    "    Name NVARCHAR(50),\n",
    "    Department NVARCHAR(50),\n",
    "    Salary INT\n",
    ")\n",
    "\"\"\"\n",
    "cursor.execute(create_table_query)\n",
    "conn.commit()\n",
    "print(\"‚úÖ Table checked/created\")\n",
    "\n",
    "# 5Ô∏è‚É£ Insert DataFrame into SQL Server\n",
    "for index, row in df.iterrows():\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO Employees (EmployeeID, Name, Department, Salary) \n",
    "        VALUES (?, ?, ?, ?)\n",
    "    \"\"\", row.EmployeeID, row.Name, row.Department, row.Salary)\n",
    "conn.commit()\n",
    "print(\"‚úÖ Data inserted successfully\")\n",
    "\n",
    "# 6Ô∏è‚É£ Close connection\n",
    "cursor.close()\n",
    "conn.close()\n",
    "print(\"‚úÖ Connection closed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "892d3c0c-e3f7-4f74-b090-320098d81ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connected to SQL Server\n",
      "‚úÖ Table checked/created\n",
      "‚úÖ Data inserted successfully\n",
      "‚úÖ Connection closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:14: SyntaxWarning: invalid escape sequence '\\M'\n",
      "<>:14: SyntaxWarning: invalid escape sequence '\\M'\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_15960\\879442624.py:14: SyntaxWarning: invalid escape sequence '\\M'\n",
      "  server = '(localdb)\\MSSQLLocalDB'        # Or 'localhost\\SQLEXPRESS' if using SQL Express\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "\n",
    "# 1Ô∏è‚É£ Create a sample DataFrame\n",
    "data = {\n",
    "    \"EmployeeID\": [1, 2, 3],\n",
    "    \"Name\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
    "    \"Department\": [\"HR\", \"IT\", \"Finance\"],\n",
    "    \"Salary\": [50000, 60000, 55000]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 2Ô∏è‚É£ Define SQL Server connection parameters\n",
    "server = '(localdb)\\MSSQLLocalDB'        # Or 'localhost\\SQLEXPRESS' if using SQL Express\n",
    "database = 'Arsipa'         # Your database name\n",
    "username = 'sa'             # SQL Server username\n",
    "password = '123'   # SQL Server password\n",
    "driver = '{ODBC Driver 17 for SQL Server}'  # Make sure this driver is installed\n",
    "\n",
    "# 3Ô∏è‚É£ Connect to SQL Server\n",
    "# conn_str with SQL Server User Authentication\n",
    "# conn_str = f'DRIVER={driver};SERVER={server};DATABASE={database};UID={username};PWD={password}'\n",
    "\n",
    "# conn_str with Windows Authntication\n",
    "conn_str = f'DRIVER={driver};SERVER={server};DATABASE={database};Trusted_Connection=yes;'\n",
    "conn = pyodbc.connect(conn_str)\n",
    "cursor = conn.cursor()\n",
    "print(\"‚úÖ Connected to SQL Server\")\n",
    "\n",
    "# 4Ô∏è‚É£ Create table (if not exists)\n",
    "create_table_query = \"\"\"\n",
    "IF NOT EXISTS (SELECT * FROM sysobjects WHERE name='Employees' AND xtype='U')\n",
    "CREATE TABLE Employees (\n",
    "    EmployeeID INT PRIMARY KEY,\n",
    "    Name NVARCHAR(50),\n",
    "    Department NVARCHAR(50),\n",
    "    Salary INT\n",
    ")\n",
    "\"\"\"\n",
    "cursor.execute(create_table_query)\n",
    "conn.commit()\n",
    "print(\"‚úÖ Table checked/created\")\n",
    "\n",
    "# 5Ô∏è‚É£ Insert DataFrame into SQL Server\n",
    "for index, row in df.iterrows():\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO Employees (EmployeeID, Name, Department, Salary) \n",
    "        VALUES (?, ?, ?, ?)\n",
    "    \"\"\", row.EmployeeID, row.Name, row.Department, row.Salary)\n",
    "conn.commit()\n",
    "print(\"‚úÖ Data inserted successfully\")\n",
    "\n",
    "# 6Ô∏è‚É£ Close connection\n",
    "cursor.close()\n",
    "conn.close()\n",
    "print(\"‚úÖ Connection closed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "470f2737-4ad4-43ce-8d6b-5416fc1f4aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Product Quantity Unit Price Total Price  Page  Table_Number  \\\n",
      "0  Smartphone        7     196.81     1377.67     1             1   \n",
      "1    Keyboard        6     351.02     2106.12     1             1   \n",
      "2     Monitor        6     393.07     2358.42     1             1   \n",
      "3      Webcam        3      97.43      292.29     1             1   \n",
      "4  Smartphone        8     380.31     3042.48     1             1   \n",
      "\n",
      "           create_date last_update  \n",
      "0  2025-09-14 09:07:03        None  \n",
      "1  2025-09-14 09:07:03        None  \n",
      "2  2025-09-14 09:07:03        None  \n",
      "3  2025-09-14 09:07:03        None  \n",
      "4  2025-09-14 09:07:03        None  \n",
      "‚úÖ Connected to SQL Server\n",
      "Table DROP  successfully.\n",
      "‚úÖ Table 'PDF_Invoice_Tables' checked/created\n",
      "‚úÖ PDF table data inserted successfully\n",
      "‚úÖ Connection closed\n"
     ]
    }
   ],
   "source": [
    "# program to retreive table from pdf and store the contents in database table.\n",
    "\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "import datetime\n",
    "\n",
    "# 1Ô∏è‚É£ Path to your PDF\n",
    "pdf_path = r\"C:\\Users\\Dell\\Desktop\\Python Practice\\outputfiles\\generated invoices/invoice_1.pdf\"\n",
    "\n",
    "# 2Ô∏è‚É£ Extract all tables from PDF\n",
    "all_tables = []\n",
    "\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    for page_number, page in enumerate(pdf.pages, start=1):\n",
    "        tables = page.extract_tables()\n",
    "        for table_number, table in enumerate(tables, start=1):\n",
    "            if len(table) > 1:  # Skip empty tables\n",
    "                df = pd.DataFrame(table[1:], columns=table[0])\n",
    "                df['Page'] = page_number\n",
    "                df['Table_Number'] = table_number\n",
    "                all_tables.append(df)\n",
    "\n",
    "# Combine all tables\n",
    "if all_tables:\n",
    "    final_df = pd.concat(all_tables, ignore_index=True)\n",
    "else:\n",
    "    final_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "# Add create_date and last_update columns\n",
    "final_df[\"create_date\"] = datetime.datetime.today().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "final_df[\"last_update\"] = None\n",
    "\n",
    "# Optional: Preview\n",
    "print(final_df.head())\n",
    "\n",
    "# 3Ô∏è‚É£ SQL Server connection parameters\n",
    "server = '(localdb)\\\\MSSQLLocalDB'  # Adjust if using SQLEXPRESS: 'localhost\\\\SQLEXPRESS'\n",
    "database = 'Arsipa'                 # Your database name\n",
    "driver = '{ODBC Driver 17 for SQL Server}'\n",
    "\n",
    "conn_str = f'DRIVER={driver};SERVER={server};DATABASE={database};Trusted_Connection=yes;'\n",
    "conn = pyodbc.connect(conn_str)\n",
    "cursor = conn.cursor()\n",
    "print(\"‚úÖ Connected to SQL Server\")\n",
    "\n",
    "\n",
    "# Truncate table\n",
    "cursor.execute(\"DROP TABLE PDF_Invoice_Tables;\")\n",
    "conn.commit()\n",
    "print(\"Table DROP  successfully.\")\n",
    "\n",
    "\n",
    "# 4Ô∏è‚É£ Create table dynamically based on PDF columns\n",
    "table_name = \"PDF_Invoice_Tables\"\n",
    "\n",
    "# Generate SQL columns from DataFrame columns (all NVARCHAR(MAX) for simplicity)\n",
    "columns_sql = \", \".join([f\"[{col}] NVARCHAR(MAX)\" for col in final_df.columns])\n",
    "create_table_query = f\"\"\"\n",
    "IF NOT EXISTS (SELECT * FROM sysobjects WHERE name='{table_name}' AND xtype='U')\n",
    "CREATE TABLE {table_name} ({columns_sql})\n",
    "\"\"\"\n",
    "cursor.execute(create_table_query)\n",
    "conn.commit()\n",
    "print(f\"‚úÖ Table '{table_name}' checked/created\")\n",
    "\n",
    "# 5Ô∏è‚É£ Insert DataFrame into SQL Server using fast executemany\n",
    "cursor.fast_executemany = True\n",
    "\n",
    "# Prepare insert statement\n",
    "columns_str = \", \".join([f\"[{col}]\" for col in final_df.columns])\n",
    "placeholders = \", \".join([\"?\"] * len(final_df.columns))\n",
    "insert_query = f\"INSERT INTO {table_name} ({columns_str}) VALUES ({placeholders})\"\n",
    "\n",
    "# Convert DataFrame to list of tuples\n",
    "data_tuples = [tuple(x) for x in final_df.values]\n",
    "cursor.executemany(insert_query, data_tuples)\n",
    "conn.commit()\n",
    "print(\"‚úÖ PDF table data inserted successfully\")\n",
    "\n",
    "# 6Ô∏è‚É£ Close connection\n",
    "cursor.close()\n",
    "conn.close()\n",
    "print(\"‚úÖ Connection closed\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
